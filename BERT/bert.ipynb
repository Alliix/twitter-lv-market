{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa29e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16f7421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train = tf.data.experimental.make_csv_dataset(\n",
    "    './../Naive_Bayes/tweets/allLabeledTweets.csv',\n",
    "    batch_size=400,\n",
    "    select_columns=['message_lowercase', 'label'],    \n",
    "    label_name='label',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)\n",
    "\n",
    "csv_val = tf.data.experimental.make_csv_dataset(\n",
    "    './../Naive_Bayes/tweets/allLabeledTweets_copy.csv',\n",
    "    batch_size=400,\n",
    "    select_columns=['message_lowercase', 'label'],    \n",
    "    label_name='label',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)\n",
    "\n",
    "csv_test = tf.data.experimental.make_csv_dataset(\n",
    "    './../Naive_Bayes/tweets/allLabeledTweets_copy_copy.csv',\n",
    "    batch_size=400,\n",
    "    select_columns=['message_lowercase', 'label'],    \n",
    "    label_name='label',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_neutral = train_df[train_df[\"label\"] == 0]\n",
    "# train_positive = train_df[train_df[\"label\"] == 1]\n",
    "# train_negative = train_df[train_df[\"label\"] == 2]\n",
    "\n",
    "# train_df = pd.concat([\n",
    "#     train_neutral.sample(87),\n",
    "#     train_positive,\n",
    "#     train_negative.sample(87)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d0667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_url = 'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3'\n",
    "encoder_url = 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4'\n",
    "\n",
    "bert_preprocess_model = hub.KerasLayer(preprocess_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99bbf177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [  101 77439 20897   106 43964 19341 19542 10147   117 10730 13410 10562]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['Sveiki! Informējam, ka saistībā ar tehniskiem uzlabojumiem šonakt laika posmā no plkst. 2.00 līdz 4.00 BITES tīklā īslaicīgi – aptuveni 3 min – nebūs pieejams internets. Ja tas nav pieejams ilgāku laiku, aicinām restartēt ierīces. Atvainojamies par sagādātajām neērtībām!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d2746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db289572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled Outputs Shape:(1, 768)\n",
      "Pooled Outputs Values:[ 0.23613809 -0.04442507  0.23505516 -0.15770182 -0.03203802  0.2451003\n",
      "  0.09333649  0.13524106 -0.20804942  0.14433675  0.08714208 -0.15120143]\n",
      "Sequence Outputs Shape:(1, 128, 768)\n",
      "Sequence Outputs Values:[[-0.27232003  0.03256002 -0.04421538 ...  0.09869212  0.35841888\n",
      "  -0.14795616]\n",
      " [-0.66119045  0.03879939  0.28476703 ... -0.34495023  0.92087734\n",
      "  -0.09457634]\n",
      " [-0.3153756  -0.16313021  0.3829687  ... -0.22015034  0.7926136\n",
      "  -0.6949453 ]\n",
      " ...\n",
      " [-0.68508047  0.3063221   0.47708553 ... -0.11326828  0.6556493\n",
      "  -0.10139327]\n",
      " [-0.2931501  -0.71528256 -0.37650025 ... -1.026762    1.0475296\n",
      "  -0.09604168]\n",
      " [-0.02384613 -1.0335578  -0.11690557 ...  0.729188    0.92268795\n",
      "  -0.96160156]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab2f5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='message_lowercase')\n",
    "    preprocessing_layer = hub.KerasLayer(preprocess_url, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(encoder_url, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875ecc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.3996465]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e561f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b6a8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "# metrics = tf.metrics.BinaryAccuracy()\n",
    "metrics = [\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d72db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = 3\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d3a74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f2b9ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (model/classifier/BiasAdd:0) = ] [[0.636165][-0.331228614][0.530802488]...] [y (Cast_3/x:0) = ] [0]\n\t [[node assert_greater_equal/Assert/AssertGuard/Assert\n (defined at C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\utils\\metrics_utils.py:608)\n]] [Op:__inference_train_function_139908]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node assert_greater_equal/Assert/AssertGuard/Assert:\nIn[0] assert_greater_equal/Assert/AssertGuard/Assert/assert_greater_equal/All:\t\nIn[1] assert_greater_equal/Assert/AssertGuard/Assert/data_0:\t\nIn[2] assert_greater_equal/Assert/AssertGuard/Assert/data_1:\t\nIn[3] assert_greater_equal/Assert/AssertGuard/Assert/data_2:\t\nIn[4] assert_greater_equal/Assert/AssertGuard/Assert/model/classifier/BiasAdd:\t\nIn[5] assert_greater_equal/Assert/AssertGuard/Assert/data_4:\t\nIn[6] assert_greater_equal/Assert/AssertGuard/Assert/Cast_3/x:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Temp/ipykernel_7784/255826947.py\", line 2, in <module>\n>>>     history = classifier_model.fit(x=csv_train,\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\training.py\", line 817, in train_step\n>>>     self.compiled_metrics.update_state(y, y_pred, sample_weight)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 460, in update_state\n>>>     metric_obj.update_state(y_t, y_p, sample_weight=mask)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 73, in decorated\n>>>     update_op = update_state_fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\metrics.py\", line 177, in update_state_fn\n>>>     return ag_update_state(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\metrics.py\", line 1399, in update_state\n>>>     return metrics_utils.update_confusion_matrix_variables(\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 608, in update_confusion_matrix_variables\n>>>     tf.compat.v1.assert_greater_equal(\n>>> \n\nFunction call stack:\ntrain_function -> assert_greater_equal_Assert_AssertGuard_false_139690\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7784/255826947.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Training model with {encoder_url}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = classifier_model.fit(x=csv_train,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcsv_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                epochs=epochs)\n",
      "\u001b[1;32m~\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (model/classifier/BiasAdd:0) = ] [[0.636165][-0.331228614][0.530802488]...] [y (Cast_3/x:0) = ] [0]\n\t [[node assert_greater_equal/Assert/AssertGuard/Assert\n (defined at C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\utils\\metrics_utils.py:608)\n]] [Op:__inference_train_function_139908]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node assert_greater_equal/Assert/AssertGuard/Assert:\nIn[0] assert_greater_equal/Assert/AssertGuard/Assert/assert_greater_equal/All:\t\nIn[1] assert_greater_equal/Assert/AssertGuard/Assert/data_0:\t\nIn[2] assert_greater_equal/Assert/AssertGuard/Assert/data_1:\t\nIn[3] assert_greater_equal/Assert/AssertGuard/Assert/data_2:\t\nIn[4] assert_greater_equal/Assert/AssertGuard/Assert/model/classifier/BiasAdd:\t\nIn[5] assert_greater_equal/Assert/AssertGuard/Assert/data_4:\t\nIn[6] assert_greater_equal/Assert/AssertGuard/Assert/Cast_3/x:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\aligo\\AppData\\Local\\Temp/ipykernel_7784/255826947.py\", line 2, in <module>\n>>>     history = classifier_model.fit(x=csv_train,\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\training.py\", line 817, in train_step\n>>>     self.compiled_metrics.update_state(y, y_pred, sample_weight)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 460, in update_state\n>>>     metric_obj.update_state(y_t, y_p, sample_weight=mask)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 73, in decorated\n>>>     update_op = update_state_fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\metrics.py\", line 177, in update_state_fn\n>>>     return ag_update_state(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\metrics.py\", line 1399, in update_state\n>>>     return metrics_utils.update_confusion_matrix_variables(\n>>> \n>>>   File \"C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 608, in update_confusion_matrix_variables\n>>>     tf.compat.v1.assert_greater_equal(\n>>> \n\nFunction call stack:\ntrain_function -> assert_greater_equal_Assert_AssertGuard_false_139690\n"
     ]
    }
   ],
   "source": [
    "print(f'Training model with {encoder_url}')\n",
    "history = classifier_model.fit(x=csv_train,\n",
    "                               validation_data=csv_val,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ae0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier_model.evaluate(csv_test)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87100095",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "# r is for \"solid red line\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = './twitter_bert_lowercase'\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bbc6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bea18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "    result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "    print(*result_for_printing, sep='\\n')\n",
    "    print()\n",
    "\n",
    "\n",
    "examples = [\n",
    "    'Tā ir brīnišķīga filma',\n",
    "    'Filma bija laba.',\n",
    "    'Filma bija meh.',\n",
    "    'Filma bija OK',\n",
    "    'Tā filma bija briesmīga...'\n",
    "]\n",
    "\n",
    "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
    "original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
    "\n",
    "print('Results from the saved model:')\n",
    "print_my_examples(examples, reloaded_results)\n",
    "print('Results from the model in memory:')\n",
    "print_my_examples(examples, original_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c413c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "venv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
