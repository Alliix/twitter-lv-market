{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "167b8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "import google_trans_new\n",
    "from google_trans_new import google_translator  \n",
    "translator = google_translator()  \n",
    "import traceback\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840fe5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install cellbell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5324b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\pyglet\\media\\codecs\\wmf.py:838: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "import cellbell\n",
    "\n",
    "def play_sound(self, etype, value, tb, tb_offset=None):\n",
    "    %ding\n",
    "    self.showtraceback((etype, value, tb), tb_offset=tb_offset)\n",
    "    print('ding worked!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "301bcaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().set_custom_exc((Exception,), play_sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "12261919",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7136/2354412189.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ding worked!\n"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "82e4a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./../Naive_Bayes/tweets/training1600000processednoemoticon.csv', names=['target','id','date','flag','user','text'])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79b6304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a1af89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174644"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./../Naive_Bayes/tweets/p_n_n_dataset.csv')\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd3b83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     77028\n",
       "positive    51994\n",
       "negative    45622\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2c66fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    77028\n",
       "1    51994\n",
       "2    45622\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {'neutral': 0, 'positive': 1, 'negative': 2}\n",
    "df['label'] = df.label.replace(label_dict) \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f345aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate_text = translator.translate(df.loc[1]['tweet']+'    ', lang_src='en', lang_tgt='lv')\n",
    "\n",
    "\n",
    "# print(df.loc[1]['tweet'])\n",
    "# print(translate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8edf5f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message_lv_google']=pd.Series(dtype='float64')\n",
    "df[pd.notnull(df['message_lv_google'])].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cfd38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34323494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "de6537f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174644"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./../Naive_Bayes/tweets/df_google_lv_1.csv')\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c1daaa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 54744\n",
    "# google_new_transError:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c80e4366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70651"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b1ed5639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                               1290000000000000000.0\n",
       "date                                                         7/22/2020\n",
       "time                                                           5:43:32\n",
       "user_id                                                    135276057.0\n",
       "username                                                    ivelisse_a\n",
       "name                                                 Poisonivy_AðŸŒŠðŸ‡µðŸ‡·ðŸ‡ºðŸ‡¸ðŸŒŠ\n",
       "tweet                @mattgaetz @realDonaldTrump Wtf, Liz Cheney re...\n",
       "language                                                            en\n",
       "label                                                                1\n",
       "message_lv_google    Kur bija Å¡is Patriks Beverly? ViÅ†Å¡ spÄ“lÄ“ ar ti...\n",
       "Name: 71874, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[start-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "13dee6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                               1080000000000000000.0\n",
       "date                                                         1/10/2019\n",
       "time                                                          13:06:48\n",
       "user_id                                           854000000000000000.0\n",
       "username                                                  sabialatina7\n",
       "name                                                       Maria Monge\n",
       "tweet                Women's Ministries Fervent Friday's January 18...\n",
       "language                                                            en\n",
       "label                                                                1\n",
       "message_lv_google    Kur bija Å¡is Patriks Beverly? ViÅ†Å¡ spÄ“lÄ“ ar ti...\n",
       "Name: 68108, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "032f9517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71108"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start+3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "478d843f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df.iloc[start:(start+3000)]\n",
    "df_1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56feabb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_to_lv = []\n",
    "for index, row in df_1.iterrows():\n",
    "    try:\n",
    "        eng_to_lv.append(translator.translate(row['tweet'].strip(), lang_src='en', lang_tgt='lv'))\n",
    "        if (index%100) == 0:\n",
    "            print(index)\n",
    "    except TypeError:\n",
    "        print(row['tweet'])\n",
    "        eng_to_lv.append(row['tweet'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e0023423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2543"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng_to_lv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c04e5250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68108"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6e5febda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aligo\\AppData\\Local\\Temp/ipykernel_7136/151635087.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['message_lv_google'][index] = translation\n"
     ]
    }
   ],
   "source": [
    "index = start\n",
    "\n",
    "for translation in eng_to_lv:\n",
    "    df['message_lv_google'][index] = translation\n",
    "    index = index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d5fd5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./../Naive_Bayes/tweets/df_google_lv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "71a87809",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = start + len(eng_to_lv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a89d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dca2cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f076ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateGoogle(start):\n",
    "    print('Start:')\n",
    "    print(start)\n",
    "    df_1 = df.iloc[start:(start+3000)]\n",
    "    eng_to_lv = []\n",
    "    for index, row in df_1.iterrows():\n",
    "        try:\n",
    "            if (index<174645):\n",
    "                eng_to_lv.append(translator.translate(row['tweet'].strip(), lang_src='en', lang_tgt='lv'))\n",
    "                insurance.append(eng_to_lv[len(eng_to_lv)-1])\n",
    "                if (index%100) == 0:\n",
    "                    print(index)\n",
    "        except TypeError:\n",
    "            print(row['tweet'])\n",
    "            eng_to_lv.append(row['tweet'].strip())\n",
    "        except Exception as e:\n",
    "            logging.error(traceback.format_exc())\n",
    "            print('Timeout Exception!')\n",
    "            index = start\n",
    "            # save to file\n",
    "            for translation in eng_to_lv:\n",
    "                df['message_lv_google'][index] = translation\n",
    "                index = index+1\n",
    "            df.to_csv('./../Naive_Bayes/tweets/df_google_lv.csv', index=False)\n",
    "            # repeat\n",
    "            start = start + len(eng_to_lv)\n",
    "            if(start<174644):\n",
    "                translateGoogle(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "translateGoogle(71874)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3cbc92bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(insurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47908f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f6b0b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>message_eng</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>65474</td>\n",
       "      <td>65474</td>\n",
       "      <td>65474</td>\n",
       "      <td>65474</td>\n",
       "      <td>65474</td>\n",
       "      <td>65473</td>\n",
       "      <td>65474</td>\n",
       "      <td>65474</td>\n",
       "      <td>65474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "      <td>11554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "      <td>44195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "      <td>7799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>38778</td>\n",
       "      <td>38778</td>\n",
       "      <td>38778</td>\n",
       "      <td>38778</td>\n",
       "      <td>38778</td>\n",
       "      <td>38777</td>\n",
       "      <td>38778</td>\n",
       "      <td>38778</td>\n",
       "      <td>38778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>6844</td>\n",
       "      <td>6844</td>\n",
       "      <td>6844</td>\n",
       "      <td>6844</td>\n",
       "      <td>6844</td>\n",
       "      <td>6843</td>\n",
       "      <td>6844</td>\n",
       "      <td>6844</td>\n",
       "      <td>6844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   date   time  user_id  username   name  tweet  \\\n",
       "label data_type                                                         \n",
       "0     train      65474  65474  65474    65474     65474  65473  65474   \n",
       "      val        11554  11554  11554    11554     11554  11554  11554   \n",
       "1     train      44195  44195  44195    44195     44195  44195  44195   \n",
       "      val         7799   7799   7799     7799      7799   7799   7799   \n",
       "2     train      38778  38778  38778    38778     38778  38777  38778   \n",
       "      val         6844   6844   6844     6844      6844   6843   6844   \n",
       "\n",
       "                 language  message_eng  \n",
       "label data_type                         \n",
       "0     train         65474        65474  \n",
       "      val           11554        11554  \n",
       "1     train         44195        44195  \n",
       "      val            7799         7799  \n",
       "2     train         38778        38778  \n",
       "      val            6844         6844  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df.label.values)\n",
    "\n",
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "df.groupby(['label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d44e80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    65474\n",
       "1    44195\n",
       "2    38778\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.data_type=='train']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb306fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    38778\n",
       "1    38778\n",
       "2    38778\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = [df[df.data_type=='val'].message_eng, df[df.data_type=='val'].label]\n",
    "\n",
    "df_train = [df[df.data_type=='train'].message_eng, df[df.data_type=='train'].label]\n",
    "df_train = pd.concat(df_train, axis=1, keys=[\"message_eng\", \"label\"])\n",
    "\n",
    "df_0 = df_train[df_train['label']==0]\n",
    "df_1 = df_train[df_train['label']==1]\n",
    "df_2 = df_train[df_train['label']==2]\n",
    "\n",
    "df_0_downsampled = df_0.sample(df_2.shape[0])\n",
    "df_1_downsampled = df_1.sample(df_2.shape[0])\n",
    "\n",
    "df_train = pd.concat([df_0_downsampled, df_1_downsampled, df_2])\n",
    "\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1952d463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', \n",
    "                                          do_lower_case=True)\n",
    "                                          \n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].message_eng.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].message_eng.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c02258e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\",\n",
    "                                                      num_labels=3,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19a0b81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "213a3185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models4/finetuned_BERT_ENG_epoch_1.model', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aeb3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c12819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "                  \n",
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "596ac477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict = {0: 0, 1: 1, 2: 2,}\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6131ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd1c0bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "147bfb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4efb1979c9456eaec3d2f8cbb4f8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/49483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16296/2526482933.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss_train_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while epoch < (epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'models4/finetuned_BERT_ENG_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    \n",
    "    epoch = epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9ef65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "venv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
