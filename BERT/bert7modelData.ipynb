{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7eabf685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, confusion_matrix\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c360f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>id</th>\n",
       "      <th>tweetId</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>language</th>\n",
       "      <th>inReplyToStatusId</th>\n",
       "      <th>inReplyToUserId</th>\n",
       "      <th>inReplyToScreenName</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>...</th>\n",
       "      <th>retweetedId</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>label</th>\n",
       "      <th>message_lowercase</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>clean_message_no_punct</th>\n",
       "      <th>clean_message_no_stopwords_from_list</th>\n",
       "      <th>clean_message_no_punct_no_stopwords_from_list</th>\n",
       "      <th>clean_message_no_punct_no_freq_stopwords</th>\n",
       "      <th>clean_message_no_freq_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rodas sajūta, ka arī @airBaltic ir kaut kāds @...</td>\n",
       "      <td>0</td>\n",
       "      <td>1213615462581440500</td>\n",
       "      <td>2020-01-05T00:17:28+00:00</td>\n",
       "      <td>lv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62004316</td>\n",
       "      <td>Edgars Eglītis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>rodas sajūta, ka arī @airbaltic ir kaut kāds @...</td>\n",
       "      <td>rodas sajūta, ka arī MENTION ir kaut kāds MENT...</td>\n",
       "      <td>rodas sajūta  ka arī MENTION ir kaut kāds MENT...</td>\n",
       "      <td>rodas sajūta , MENTION kāds MENTION kaktu kant...</td>\n",
       "      <td>rodas sajūta MENTION kāds MENTION kaktu kantor...</td>\n",
       "      <td>rodas sajūta MENTION kaut MENTION kaktu kantor...</td>\n",
       "      <td>rodas sajūta , MENTION kaut MENTION kaktu kant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amsterdama, @airBaltic  smukulītes 👍🏻 https://...</td>\n",
       "      <td>0</td>\n",
       "      <td>1213740889476128800</td>\n",
       "      <td>2020-01-05T08:35:52+00:00</td>\n",
       "      <td>lv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213752948</td>\n",
       "      <td>Dairis Kuciks</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>amsterdama, @airbaltic  smukulītes 👍🏻 https://...</td>\n",
       "      <td>amsterdama, MENTION smukulītes 👍🏻 URL</td>\n",
       "      <td>amsterdama  MENTION smukulītes 👍🏻 URL</td>\n",
       "      <td>amsterdama , MENTION smukulītes 👍🏻 URL</td>\n",
       "      <td>amsterdama MENTION smukulītes 👍🏻 URL</td>\n",
       "      <td>amsterdama MENTION smukulītes 👍🏻 URL</td>\n",
       "      <td>amsterdama , MENTION smukulītes 👍🏻 URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kārtējo reizi... \\r\\n@airBaltic vakar raudošai...</td>\n",
       "      <td>0</td>\n",
       "      <td>1214174186069012500</td>\n",
       "      <td>2020-01-06T13:17:38+00:00</td>\n",
       "      <td>lv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1107743410646069200</td>\n",
       "      <td>Selma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>kārtējo reizi... \\r\\n@airbaltic vakar raudošai...</td>\n",
       "      <td>kārtējo reizi... MENTION vakar raudošai sievie...</td>\n",
       "      <td>kārtējo reizi    MENTION vakar raudošai sievie...</td>\n",
       "      <td>kārtējo reizi ... MENTION vakar raudošai sievi...</td>\n",
       "      <td>kārtējo reizi MENTION vakar raudošai sievietei...</td>\n",
       "      <td>kārtējo reizi MENTION vakar raudošai sievietei...</td>\n",
       "      <td>kārtējo reizi ... MENTION vakar raudošai sievi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.05% airBaltic akciju pieder Latvijas valsti...</td>\n",
       "      <td>0</td>\n",
       "      <td>1214176732456075300</td>\n",
       "      <td>2020-01-06T13:27:45+00:00</td>\n",
       "      <td>lv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1107743410646069200</td>\n",
       "      <td>Selma</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80.05% airbaltic akciju pieder latvijas valsti...</td>\n",
       "      <td>NMBR % airbaltic akciju pieder latvijas valsti...</td>\n",
       "      <td>NMBR   airbaltic akciju pieder latvijas valsti...</td>\n",
       "      <td>NMBR % airbaltic akciju pieder latvijas valsti...</td>\n",
       "      <td>NMBR airbaltic akciju pieder latvijas valstij ...</td>\n",
       "      <td>NMBR airbaltic akciju pieder latvijas valstij ...</td>\n",
       "      <td>NMBR % airbaltic akciju pieder latvijas valsti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laba ideja lidojumiem ar @airBaltic https://t....</td>\n",
       "      <td>0</td>\n",
       "      <td>1214197047382941700</td>\n",
       "      <td>2020-01-06T14:48:29+00:00</td>\n",
       "      <td>lv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110783755</td>\n",
       "      <td>Inga Gorbunova</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>laba ideja lidojumiem ar @airbaltic https://t....</td>\n",
       "      <td>laba ideja lidojumiem ar MENTION URL</td>\n",
       "      <td>laba ideja lidojumiem ar MENTION URL</td>\n",
       "      <td>laba ideja lidojumiem MENTION URL</td>\n",
       "      <td>laba ideja lidojumiem MENTION URL</td>\n",
       "      <td>laba ideja lidojumiem MENTION URL</td>\n",
       "      <td>laba ideja lidojumiem MENTION URL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  id              tweetId  \\\n",
       "0  Rodas sajūta, ka arī @airBaltic ir kaut kāds @...   0  1213615462581440500   \n",
       "1  Amsterdama, @airBaltic  smukulītes 👍🏻 https://...   0  1213740889476128800   \n",
       "2  Kārtējo reizi... \\r\\n@airBaltic vakar raudošai...   0  1214174186069012500   \n",
       "3  80.05% airBaltic akciju pieder Latvijas valsti...   0  1214176732456075300   \n",
       "4  Laba ideja lidojumiem ar @airBaltic https://t....   0  1214197047382941700   \n",
       "\n",
       "                   createdAt language  inReplyToStatusId  inReplyToUserId  \\\n",
       "0  2020-01-05T00:17:28+00:00       lv                NaN              NaN   \n",
       "1  2020-01-05T08:35:52+00:00       lv                NaN              NaN   \n",
       "2  2020-01-06T13:17:38+00:00       lv                NaN              NaN   \n",
       "3  2020-01-06T13:27:45+00:00       lv                NaN              NaN   \n",
       "4  2020-01-06T14:48:29+00:00       lv                NaN              NaN   \n",
       "\n",
       "   inReplyToScreenName               userId        userName  ... retweetedId  \\\n",
       "0                  NaN             62004316  Edgars Eglītis  ...         NaN   \n",
       "1                  NaN            213752948   Dairis Kuciks  ...         NaN   \n",
       "2                  NaN  1107743410646069200           Selma  ...         NaN   \n",
       "3                  NaN  1107743410646069200           Selma  ...         NaN   \n",
       "4                  NaN            110783755  Inga Gorbunova  ...         NaN   \n",
       "\n",
       "   retweetCount label                                  message_lowercase  \\\n",
       "0             0     2  rodas sajūta, ka arī @airbaltic ir kaut kāds @...   \n",
       "1             0     1  amsterdama, @airbaltic  smukulītes 👍🏻 https://...   \n",
       "2            73     2  kārtējo reizi... \\r\\n@airbaltic vakar raudošai...   \n",
       "3             2     2  80.05% airbaltic akciju pieder latvijas valsti...   \n",
       "4             4     0  laba ideja lidojumiem ar @airbaltic https://t....   \n",
       "\n",
       "                                       clean_message  \\\n",
       "0  rodas sajūta, ka arī MENTION ir kaut kāds MENT...   \n",
       "1              amsterdama, MENTION smukulītes 👍🏻 URL   \n",
       "2  kārtējo reizi... MENTION vakar raudošai sievie...   \n",
       "3  NMBR % airbaltic akciju pieder latvijas valsti...   \n",
       "4               laba ideja lidojumiem ar MENTION URL   \n",
       "\n",
       "                              clean_message_no_punct  \\\n",
       "0  rodas sajūta  ka arī MENTION ir kaut kāds MENT...   \n",
       "1              amsterdama  MENTION smukulītes 👍🏻 URL   \n",
       "2  kārtējo reizi    MENTION vakar raudošai sievie...   \n",
       "3  NMBR   airbaltic akciju pieder latvijas valsti...   \n",
       "4               laba ideja lidojumiem ar MENTION URL   \n",
       "\n",
       "                clean_message_no_stopwords_from_list  \\\n",
       "0  rodas sajūta , MENTION kāds MENTION kaktu kant...   \n",
       "1             amsterdama , MENTION smukulītes 👍🏻 URL   \n",
       "2  kārtējo reizi ... MENTION vakar raudošai sievi...   \n",
       "3  NMBR % airbaltic akciju pieder latvijas valsti...   \n",
       "4                  laba ideja lidojumiem MENTION URL   \n",
       "\n",
       "       clean_message_no_punct_no_stopwords_from_list  \\\n",
       "0  rodas sajūta MENTION kāds MENTION kaktu kantor...   \n",
       "1               amsterdama MENTION smukulītes 👍🏻 URL   \n",
       "2  kārtējo reizi MENTION vakar raudošai sievietei...   \n",
       "3  NMBR airbaltic akciju pieder latvijas valstij ...   \n",
       "4                  laba ideja lidojumiem MENTION URL   \n",
       "\n",
       "            clean_message_no_punct_no_freq_stopwords  \\\n",
       "0  rodas sajūta MENTION kaut MENTION kaktu kantor...   \n",
       "1               amsterdama MENTION smukulītes 👍🏻 URL   \n",
       "2  kārtējo reizi MENTION vakar raudošai sievietei...   \n",
       "3  NMBR airbaltic akciju pieder latvijas valstij ...   \n",
       "4                  laba ideja lidojumiem MENTION URL   \n",
       "\n",
       "                     clean_message_no_freq_stopwords  \n",
       "0  rodas sajūta , MENTION kaut MENTION kaktu kant...  \n",
       "1             amsterdama , MENTION smukulītes 👍🏻 URL  \n",
       "2  kārtējo reizi ... MENTION vakar raudošai sievi...  \n",
       "3  NMBR % airbaltic akciju pieder latvijas valsti...  \n",
       "4                  laba ideja lidojumiem MENTION URL  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./../Naive_Bayes/tweets/allLabeledTweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eb5a6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>id</th>\n",
       "      <th>tweetId</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>language</th>\n",
       "      <th>inReplyToStatusId</th>\n",
       "      <th>inReplyToUserId</th>\n",
       "      <th>inReplyToScreenName</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>...</th>\n",
       "      <th>placeType</th>\n",
       "      <th>retweetedId</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>message_lowercase</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>clean_message_no_punct</th>\n",
       "      <th>clean_message_no_stopwords_from_list</th>\n",
       "      <th>clean_message_no_punct_no_stopwords_from_list</th>\n",
       "      <th>clean_message_no_punct_no_freq_stopwords</th>\n",
       "      <th>clean_message_no_freq_stopwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 message   id  tweetId  createdAt  language  \\\n",
       "label data_type                                               \n",
       "0     train          205  205      205        205       205   \n",
       "      val             37   37       37         37        37   \n",
       "1     train           71   71       71         71        71   \n",
       "      val             13   13       13         13        13   \n",
       "2     train          103  103      103        103       103   \n",
       "      val             18   18       18         18        18   \n",
       "\n",
       "                 inReplyToStatusId  inReplyToUserId  inReplyToScreenName  \\\n",
       "label data_type                                                            \n",
       "0     train                      0                0                    0   \n",
       "      val                        0                0                    0   \n",
       "1     train                      0                0                    0   \n",
       "      val                        0                0                    0   \n",
       "2     train                      0                0                    0   \n",
       "      val                        0                0                    0   \n",
       "\n",
       "                 userId  userName  ...  placeType  retweetedId  retweetCount  \\\n",
       "label data_type                    ...                                         \n",
       "0     train         205       205  ...          9            0           205   \n",
       "      val            37        37  ...          0            0            37   \n",
       "1     train          71        71  ...          5            0            71   \n",
       "      val            13        13  ...          4            0            13   \n",
       "2     train         103       103  ...         10            0           103   \n",
       "      val            18        18  ...          0            0            18   \n",
       "\n",
       "                 message_lowercase  clean_message  clean_message_no_punct  \\\n",
       "label data_type                                                             \n",
       "0     train                    205            205                     205   \n",
       "      val                       37             37                      37   \n",
       "1     train                     71             71                      71   \n",
       "      val                       13             13                      13   \n",
       "2     train                    103            103                     103   \n",
       "      val                       18             18                      18   \n",
       "\n",
       "                 clean_message_no_stopwords_from_list  \\\n",
       "label data_type                                         \n",
       "0     train                                       205   \n",
       "      val                                          37   \n",
       "1     train                                        71   \n",
       "      val                                          13   \n",
       "2     train                                       103   \n",
       "      val                                          18   \n",
       "\n",
       "                 clean_message_no_punct_no_stopwords_from_list  \\\n",
       "label data_type                                                  \n",
       "0     train                                                205   \n",
       "      val                                                   37   \n",
       "1     train                                                 71   \n",
       "      val                                                   13   \n",
       "2     train                                                103   \n",
       "      val                                                   18   \n",
       "\n",
       "                 clean_message_no_punct_no_freq_stopwords  \\\n",
       "label data_type                                             \n",
       "0     train                                           205   \n",
       "      val                                              37   \n",
       "1     train                                            71   \n",
       "      val                                              13   \n",
       "2     train                                           103   \n",
       "      val                                              18   \n",
       "\n",
       "                 clean_message_no_freq_stopwords  \n",
       "label data_type                                   \n",
       "0     train                                  205  \n",
       "      val                                     37  \n",
       "1     train                                   71  \n",
       "      val                                     13  \n",
       "2     train                                  103  \n",
       "      val                                     18  \n",
       "\n",
       "[6 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df.label.values)\n",
    "\n",
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "df.groupby(['label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a141637c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>id</th>\n",
       "      <th>tweetId</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>language</th>\n",
       "      <th>inReplyToStatusId</th>\n",
       "      <th>inReplyToUserId</th>\n",
       "      <th>inReplyToScreenName</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>...</th>\n",
       "      <th>placeType</th>\n",
       "      <th>retweetedId</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>message_lowercase</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>clean_message_no_punct</th>\n",
       "      <th>clean_message_no_stopwords_from_list</th>\n",
       "      <th>clean_message_no_punct_no_stopwords_from_list</th>\n",
       "      <th>clean_message_no_punct_no_freq_stopwords</th>\n",
       "      <th>clean_message_no_freq_stopwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 message   id  tweetId  createdAt  language  \\\n",
       "label data_type                                               \n",
       "0     train          205  205      205        205       205   \n",
       "      val             37   37       37         37        37   \n",
       "1     train           71   71       71         71        71   \n",
       "      val             13   13       13         13        13   \n",
       "2     train          103  103      103        103       103   \n",
       "      val             18   18       18         18        18   \n",
       "\n",
       "                 inReplyToStatusId  inReplyToUserId  inReplyToScreenName  \\\n",
       "label data_type                                                            \n",
       "0     train                      0                0                    0   \n",
       "      val                        0                0                    0   \n",
       "1     train                      0                0                    0   \n",
       "      val                        0                0                    0   \n",
       "2     train                      0                0                    0   \n",
       "      val                        0                0                    0   \n",
       "\n",
       "                 userId  userName  ...  placeType  retweetedId  retweetCount  \\\n",
       "label data_type                    ...                                         \n",
       "0     train         205       205  ...          9            0           205   \n",
       "      val            37        37  ...          0            0            37   \n",
       "1     train          71        71  ...          5            0            71   \n",
       "      val            13        13  ...          4            0            13   \n",
       "2     train         103       103  ...         10            0           103   \n",
       "      val            18        18  ...          0            0            18   \n",
       "\n",
       "                 message_lowercase  clean_message  clean_message_no_punct  \\\n",
       "label data_type                                                             \n",
       "0     train                    205            205                     205   \n",
       "      val                       37             37                      37   \n",
       "1     train                     71             71                      71   \n",
       "      val                       13             13                      13   \n",
       "2     train                    103            103                     103   \n",
       "      val                       18             18                      18   \n",
       "\n",
       "                 clean_message_no_stopwords_from_list  \\\n",
       "label data_type                                         \n",
       "0     train                                       205   \n",
       "      val                                          37   \n",
       "1     train                                        71   \n",
       "      val                                          13   \n",
       "2     train                                       103   \n",
       "      val                                          18   \n",
       "\n",
       "                 clean_message_no_punct_no_stopwords_from_list  \\\n",
       "label data_type                                                  \n",
       "0     train                                                205   \n",
       "      val                                                   37   \n",
       "1     train                                                 71   \n",
       "      val                                                   13   \n",
       "2     train                                                103   \n",
       "      val                                                   18   \n",
       "\n",
       "                 clean_message_no_punct_no_freq_stopwords  \\\n",
       "label data_type                                             \n",
       "0     train                                           205   \n",
       "      val                                              37   \n",
       "1     train                                            71   \n",
       "      val                                              13   \n",
       "2     train                                           103   \n",
       "      val                                              18   \n",
       "\n",
       "                 clean_message_no_freq_stopwords  \n",
       "label data_type                                   \n",
       "0     train                                  205  \n",
       "      val                                     37  \n",
       "1     train                                   71  \n",
       "      val                                     13  \n",
       "2     train                                  103  \n",
       "      val                                     18  \n",
       "\n",
       "[6 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e65c15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find max length for tokenizer\n",
    "token_lens = []\n",
    "for txt in list(df[df.data_type=='train'].message.values):\n",
    "    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "    token_lens.append(len(tokens))\n",
    "    \n",
    "sns.displot(token_lens)\n",
    "plt.xlim([0, 200])\n",
    "plt.xlabel('Token count')\n",
    "plt.show()\n",
    "\n",
    "#165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05259c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd6d9d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\aligo\\Documents\\DEV\\twitter-lv-market\\venv38\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(379, 68)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].message.values, \n",
    "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "    return_attention_mask=True, \n",
    "    padding='max_length', \n",
    "    max_length=165, \n",
    "    truncation=True,\n",
    "    return_tensors='pt' # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].message.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    padding='max_length', \n",
    "    max_length=165, \n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6875a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27193bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\",\n",
    "                                                      num_labels=3,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6ccb608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad43df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6b3399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcd7b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e4f5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ef885f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c1461233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1897f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6ad95344744fe4aba74103e1d65952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.8318500121630082\n",
      "Validation loss: 0.8297346802833288\n",
      "F1 Score (Weighted): 0.6548345709731347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.687879205366054\n",
      "Validation loss: 0.7412645181883937\n",
      "F1 Score (Weighted): 0.7194852941176472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.5003164832839581\n",
      "Validation loss: 0.9010133057751734\n",
      "F1 Score (Weighted): 0.6970735662686127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.3564117879966113\n",
      "Validation loss: 1.025445687746548\n",
      "F1 Score (Weighted): 0.6880736618971913\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.26737557249657046\n",
      "Validation loss: 1.0686793172853473\n",
      "F1 Score (Weighted): 0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'models7/finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161a8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddacf197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "model.load_state_dict(torch.load('models7/finetuned_BERT_epoch_2.model', map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1022c599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8858358   0.14105213 -0.513066  ]\n",
      " [-1.6035718  -0.48101157  1.3492693 ]\n",
      " [ 3.164962   -1.0567942  -1.5544996 ]\n",
      " [-0.32793224 -0.03681315  0.41687918]\n",
      " [ 0.3376204   0.66205615 -0.63059354]\n",
      " [ 0.63508046  0.5287831  -0.79365593]\n",
      " [ 0.41032517  0.72027165 -0.6245356 ]\n",
      " [ 0.06367293  0.625394   -0.4108181 ]\n",
      " [ 3.112114   -1.1128235  -1.621546  ]\n",
      " [ 3.1621695  -1.1352627  -1.5408473 ]\n",
      " [-1.0181398  -0.3259492   0.7194981 ]\n",
      " [ 2.7567148  -1.013685   -1.2819393 ]\n",
      " [-1.6487277  -0.49759245  1.5455343 ]\n",
      " [-1.2877803  -0.56269956  1.39223   ]\n",
      " [ 3.129787   -1.065842   -1.6121141 ]\n",
      " [ 3.1347623  -1.1690668  -1.6202205 ]\n",
      " [ 3.1587276  -1.1816691  -1.5806907 ]\n",
      " [ 3.1788003  -1.1569557  -1.5854945 ]\n",
      " [ 3.178621   -1.1501609  -1.5686334 ]\n",
      " [ 3.1200252  -1.0546885  -1.6150074 ]\n",
      " [ 3.08359    -1.188403   -1.5352881 ]\n",
      " [ 0.45625094 -0.10132962  0.03260231]\n",
      " [ 0.4523208   0.08580122 -0.06870622]\n",
      " [-0.9743455  -0.19785765  0.45859066]\n",
      " [-0.71022975  0.02929774  0.36701196]\n",
      " [-0.74669856 -0.41597712  0.9957889 ]\n",
      " [ 2.424883   -0.42810118 -1.3356998 ]\n",
      " [ 3.1578898  -1.0635892  -1.5622929 ]\n",
      " [ 2.6672077  -0.8242137  -1.5127846 ]\n",
      " [ 3.0537338  -1.0328099  -1.5745274 ]\n",
      " [ 3.0792375  -1.065893   -1.5588901 ]\n",
      " [ 3.107059   -1.0725449  -1.5970193 ]\n",
      " [ 2.9883668  -0.88615936 -1.5218524 ]\n",
      " [-1.63583    -0.13527521  0.84804106]\n",
      " [ 2.3837388  -0.6518492  -1.1411948 ]\n",
      " [-0.21087292 -0.2761935   0.47836223]\n",
      " [-0.988721   -0.48218107  1.1786978 ]\n",
      " [ 1.9360162  -0.40138242 -1.1024001 ]\n",
      " [ 0.6448143  -0.08864407 -0.6613624 ]\n",
      " [-1.4652574  -0.17891467  1.1661999 ]\n",
      " [ 0.575024    0.20489657 -0.6013808 ]\n",
      " [ 2.1525178  -0.49449432 -1.1050613 ]\n",
      " [ 3.02294    -0.91784364 -1.6171653 ]\n",
      " [-1.3300242  -0.5339346   1.7046657 ]\n",
      " [-0.9350924   0.03288881  0.32892334]\n",
      " [ 3.123106   -0.9403704  -1.488919  ]\n",
      " [ 0.2081114  -0.14422783 -0.12973185]\n",
      " [ 3.17777    -1.13655    -1.6150731 ]\n",
      " [ 0.7171125   0.33002746 -0.463213  ]\n",
      " [ 2.6767116  -0.60399246 -1.6374478 ]\n",
      " [ 3.1703885  -1.0939987  -1.6018882 ]\n",
      " [ 3.1312902  -1.1042598  -1.6488807 ]\n",
      " [ 3.2066464  -1.0069273  -1.5733395 ]\n",
      " [ 3.200929   -1.1051269  -1.5924466 ]\n",
      " [ 3.171455   -1.073373   -1.6189593 ]\n",
      " [-1.6059885  -0.30543432  1.3877512 ]\n",
      " [ 3.04279    -1.0481677  -1.5576292 ]\n",
      " [-1.3141589  -0.11602661  1.124268  ]\n",
      " [ 0.42944944  0.08851936 -0.26096115]\n",
      " [ 2.0633688  -0.5793171  -0.9413366 ]\n",
      " [ 3.1555212  -1.0577799  -1.5234125 ]\n",
      " [-1.508191   -0.49442297  1.649333  ]\n",
      " [ 2.9142222  -0.8646746  -1.5713792 ]\n",
      " [-1.5633012  -0.30752832  1.2055061 ]\n",
      " [-1.2895739  -0.22122946  1.0384316 ]\n",
      " [-1.64592    -0.4079661   1.6584332 ]\n",
      " [-1.7597399  -0.25384587  1.0063128 ]\n",
      " [-1.1495715  -0.38138267  0.8524042 ]]\n",
      "[1 2 0 2 1 0 1 1 0 0 1 2 2 2 0 0 0 0 0 0 0 2 0 0 0 2 2 1 0 0 0 0 1 2 0 2 2\n",
      " 0 1 1 1 0 0 2 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 2 2 2 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3e0a8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 2 1 0 1 1 0 0 2 0 2 2 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 2 0 2 2\n",
      " 0 0 2 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 2 0 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "preds_flat = np.argmax(predictions, axis=1).flatten()\n",
    "print(preds_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0613082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        37\n",
      "           1       1.00      0.23      0.38        13\n",
      "           2       0.64      0.78      0.70        18\n",
      "\n",
      "    accuracy                           0.75        68\n",
      "   macro avg       0.81      0.64      0.64        68\n",
      "weighted avg       0.79      0.75      0.72        68\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">actual</th>\n",
       "      <th>neutral</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted                  \n",
       "                  neutral positive negative\n",
       "actual neutral         34        0        3\n",
       "       positive         5        3        5\n",
       "       negative         4        0       14"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(true_vals, preds_flat))\n",
    "pd.DataFrame(confusion_matrix(true_vals, preds_flat),\n",
    "        index = [['actual', 'actual', 'actual'], ['neutral', 'positive', 'negative']],\n",
    "        columns = [['predicted', 'predicted', 'predicted'], ['neutral', 'positive', 'negative']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f71753c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "# test_pred = model.predict(X_test)\n",
    "# print(test_pred)\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6820df29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'LABEL_0', 'score': 0.4163522720336914}, {'label': 'LABEL_1', 'score': 0.3224363625049591}, {'label': 'LABEL_2', 'score': 0.2612113058567047}], [{'label': 'LABEL_0', 'score': 0.3587017357349396}, {'label': 'LABEL_1', 'score': 0.31799253821372986}, {'label': 'LABEL_2', 'score': 0.32330572605133057}]]\n"
     ]
    }
   ],
   "source": [
    "res = pipe([\"I love this movie!\", \"I hate this movie!\"])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1c9a6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_preds(res):\n",
    "    all_vals = []\n",
    "    for arr in res:\n",
    "        vals = []\n",
    "        for label_values in arr:\n",
    "            vals.append(label_values['score'])\n",
    "        all_vals.append(vals)\n",
    "\n",
    "    p = np.argmax(all_vals, axis=1).flatten()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7639bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "    result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {trans_preds(results)[i]}'\n",
    "                         for i in range(len(inputs))]\n",
    "    print(*result_for_printing, sep='\\n')\n",
    "    print()\n",
    "    \n",
    "examples = [\n",
    "    'Tā ir brīnišķīga filma',\n",
    "    'Viss ir slikti',\n",
    "    '❤',\n",
    "    'Filma bija OK',\n",
    "    'Tā filma bija briesmīga...'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f90a6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipe(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5ee9e20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: Tā ir brīnišķīga filma         : score: 0\n",
      "input: Viss ir slikti                 : score: 2\n",
      "input: ❤                              : score: 1\n",
      "input: Filma bija OK                  : score: 0\n",
      "input: Tā filma bija briesmīga...     : score: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_my_examples(examples, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b211ae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=tensor(1.0453, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.2972,  0.1839, -0.1386]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # need dtype=float for BCEWithLogitsLoss\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3edf1ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.batch_encode_plus(\n",
    "    examples, \n",
    "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "    return_attention_mask=True, \n",
    "    padding='max_length', \n",
    "    max_length=165, \n",
    "    truncation=True,\n",
    "    return_tensors='pt' # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "# input_ids = inputs['input_ids']\n",
    "# attention_masks = inputs['attention_mask']\n",
    "# labels = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "# dataset_inputs = TensorDataset(inputs)\n",
    "\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ef2dad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.1018, -0.1069, -0.3755],\n",
       "        [ 0.4777,  0.0176,  0.1579],\n",
       "        [ 0.9149,  0.0210, -0.1788],\n",
       "        [ 0.8174,  0.1800, -0.1088],\n",
       "        [-0.7169, -0.5046,  0.9797]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0fb90810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1017747 , -0.1069112 , -0.37547195],\n",
       "       [ 0.477729  ,  0.01759287,  0.15792726],\n",
       "       [ 0.91488606,  0.02098612, -0.17877908],\n",
       "       [ 0.8173776 ,  0.1799692 , -0.10880005],\n",
       "       [-0.71693987, -0.5045896 ,  0.9797273 ]], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = outputs.logits\n",
    "logits = logits.detach().cpu().numpy()\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "25a86693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "pr = np.argmax(logits, axis=1).flatten()\n",
    "print(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b68f6cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(bert_model, inputs):\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        inputs, \n",
    "        add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "        return_attention_mask=True, \n",
    "        padding='max_length', \n",
    "        max_length=165, \n",
    "        truncation=True,\n",
    "        return_tensors='pt' # Return PyTorch tensors\n",
    "    )\n",
    "    outputs = bert_model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    predictions = np.argmax(logits, axis=1).flatten()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "78ee6939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc5208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "venv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
